{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b14750",
   "metadata": {},
   "source": [
    "# **11. Advanced Features & Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e7005",
   "metadata": {},
   "source": [
    "## üìâ 4. **Memory Usage & Efficiency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f238fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25150c2",
   "metadata": {},
   "source": [
    "## üìå 1. **Purpose & When to Use It**\n",
    "\n",
    "### üéØ **Purpose**:\n",
    "\n",
    "Memory usage optimization focuses on **reducing the RAM** consumed by pandas DataFrames, which is critical when working with **large datasets**. By controlling data types and memory representations, you can:\n",
    "\n",
    "* Load large datasets without crashing\n",
    "* Speed up operations due to smaller memory footprint\n",
    "* Reduce computational cost and latency in production environments\n",
    "\n",
    "### üìÖ **When to Use It**:\n",
    "\n",
    "* When your dataset has **millions of rows**\n",
    "* When you're hitting **memory errors**\n",
    "* Before **saving DataFrames to disk** to reduce file size\n",
    "* When preparing **datasets for machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fc299",
   "metadata": {},
   "source": [
    "## üß† 2. **Different Methods and Techniques**\n",
    "\n",
    "| Technique                    | Description                                                        |\n",
    "| ---------------------------- | ------------------------------------------------------------------ |\n",
    "| `.memory_usage()`            | Inspect memory consumption of each column                          |\n",
    "| `astype()`                   | Convert columns to more efficient data types                       |\n",
    "| **Downcasting**              | Reduce float/int types to lower precision (e.g., `int64` ‚Üí `int8`) |\n",
    "| **Categorical data**         | Optimize memory for repetitive strings/objects                     |\n",
    "| `convert_dtypes()`           | Automatically infer better memory-efficient types                  |\n",
    "| **Read CSV with types**      | Define `dtype` argument while reading files                        |\n",
    "| **Drop unnecessary columns** | Free up space early in your pipeline                               |\n",
    "| **Use `chunksize`**          | Load large files in small parts to avoid memory peaks              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fddff",
   "metadata": {},
   "source": [
    "## üß™ 3. **Examples with Code**\n",
    "\n",
    "### üîπ a) Check memory usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('large_dataset.csv')\n",
    "print(df.memory_usage(deep=True))  # Shows memory per column\n",
    "print(df.memory_usage(deep=True).sum() / 1024**2, \"MB\")  # Total in MB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ b) Downcasting numeric columns\n",
    "\n",
    "```python\n",
    "df['int_col'] = pd.to_numeric(df['int_col'], downcast='integer')\n",
    "df['float_col'] = pd.to_numeric(df['float_col'], downcast='float')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ c) Convert object columns to `category`\n",
    "\n",
    "```python\n",
    "df['city'] = df['city'].astype('category')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ d) Automatic data type optimization\n",
    "\n",
    "```python\n",
    "df = df.convert_dtypes()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ e) Optimize while reading CSV\n",
    "\n",
    "```python\n",
    "dtypes = {'user_id': 'int32', 'price': 'float32', 'category': 'category'}\n",
    "df = pd.read_csv('sales.csv', dtype=dtypes)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ f) Load large file in chunks\n",
    "\n",
    "```python\n",
    "chunks = pd.read_csv('big.csv', chunksize=50000)\n",
    "for chunk in chunks:\n",
    "    process(chunk)  # Your custom logic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff50cd0",
   "metadata": {},
   "source": [
    "## ‚ö° 4. **Performance Considerations**\n",
    "\n",
    "| Optimization             | Memory Saved             | Speed Impact                     |\n",
    "| ------------------------ | ------------------------ | -------------------------------- |\n",
    "| Downcasting integers     | High                     | Slight speed-up                  |\n",
    "| Using categories         | Very High (up to 80‚Äì90%) | Faster groupby/sorting           |\n",
    "| Dropping unused columns  | High                     | Faster overall processing        |\n",
    "| Reading with `dtype`     | Medium                   | Avoids upcasting during read     |\n",
    "| Using `convert_dtypes()` | Moderate                 | Automated but not always optimal |\n",
    "| Chunking                 | Prevents crash           | Slightly slower but safer        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe5e2d",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è 5. **Common Pitfalls & Mistakes**\n",
    "\n",
    "1. ‚ùå **Leaving default data types** ‚Äî `int64`, `float64`, and `object` take more memory than necessary\n",
    "2. ‚ùå **Ignoring string/object columns** ‚Äî these consume the most memory\n",
    "3. ‚ùå **Downcasting without checking value range** ‚Äî could cause **overflow or precision loss**\n",
    "4. ‚ùå **Using category for high-cardinality columns** ‚Äî may actually **increase memory**\n",
    "5. ‚ùå **Reading large CSVs without `dtype` or `chunksize`** ‚Äî leads to memory crashes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630b386",
   "metadata": {},
   "source": [
    "## ‚úÖ 6. **Best Practices**\n",
    "\n",
    "* ‚úÖ Always **inspect memory** using `.memory_usage(deep=True)`\n",
    "* ‚úÖ Use `astype()` to downcast numeric types appropriately\n",
    "* ‚úÖ Convert repeated strings to `category` when cardinality is low\n",
    "* ‚úÖ Drop or exclude **unnecessary columns** early\n",
    "* ‚úÖ Pass `dtype` explicitly when reading large files\n",
    "* ‚úÖ Use **`chunksize`** for massive datasets\n",
    "* ‚úÖ Combine memory optimization with performance techniques (vectorization, method chaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88bb078",
   "metadata": {},
   "source": [
    "## üíº 7. **Use Cases in Real Projects**\n",
    "\n",
    "| Domain                 | Use Case                                                                            |\n",
    "| ---------------------- | ----------------------------------------------------------------------------------- |\n",
    "| üè• Healthcare          | Large EHR (Electronic Health Records) datasets with categorical codes               |\n",
    "| üì¶ Logistics           | Shipment logs with repeated locations, product types                                |\n",
    "| üõçÔ∏è Retail             | Millions of order rows stored with default `object` types ‚Üí converted to `category` |\n",
    "| üìà Finance             | High-volume tick data downcasted to `float32` and `int32`                           |\n",
    "| üìä Marketing Analytics | Read billions of clickstream rows using `chunksize` and optimized types             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb5bdd",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "Memory usage and efficiency techniques are **critical** for working with large datasets. By applying **smart data typing, chunking, and memory profiling**, you can handle big data even on modest hardware, write scalable pipelines, and reduce runtime and resource costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87414b4e",
   "metadata": {},
   "source": [
    "<center><b>Thanks</b></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
